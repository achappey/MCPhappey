using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Net.Http.Headers;
using System.Runtime.Serialization;
using System.Text;
using System.Text.Json;
using System.Text.Json.Serialization;
using Json.More;
using MCPhappey.Common.Extensions;
using MCPhappey.Core.Extensions;
using MCPhappey.Core.Services;
using MCPhappey.Tools.AIML.Images;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.KernelMemory.Pipeline;
using ModelContextProtocol.Protocol;
using ModelContextProtocol.Server;

namespace MCPhappey.Tools.AIML.Video;

public static class AIMLVideo
{
    private static readonly string BASE_URL = "https://api.aimlapi.com/v2/video/generations";

    private static readonly string PIXVERSE_BASE_URL = "https://api.aimlapi.com/v2/generate/video/pixverse/generation";

    [Description("Generate a short AI video using PixVerse v5. Provide a prompt describing the scene, subject, or action. Returns a generation ID for asynchronous processing.")]
    [McpServerTool(
        Title = "Generate video with PixVerse v5",
        Name = "aiml_video_pixverse_generate",
        Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_PixVerseGenerate(
        [Description("Prompt describing the video content (scene, subject, action, atmosphere, etc.)."), MaxLength(4000)] string prompt,
        IServiceProvider serviceProvider,
        RequestContext<CallToolRequestParams> requestContext,
        [Description("Aspect ratio of the generated video. Default: 16:9")] AspectRatio aspectRatio = AspectRatio.Ratio_16x9,
        [Description("Video resolution. Default: 720p")] Resolution resolution = Resolution.p720,
        [Description("Duration of the output video in seconds (5 or 8).")] Duration duration = Duration.Seconds5,
        [Description("Optional description of what to avoid in the video.")] string? negativePrompt = null,
        [Description("Visual style of the generated video.")] VideoStyle style = VideoStyle.Anime,
        [Description("Optional seed for deterministic results.")] int? seed = null,
        [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
        CancellationToken cancellationToken = default)
        => await requestContext.WithExceptionCheck(async () =>
    {
        ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);

        var settings = serviceProvider.GetRequiredService<AIMLSettings>();
        var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

        // Step 1: Ask user for missing input
        var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
            new AIMLPixVerseVideoRequest
            {
                Prompt = prompt,
                AspectRatio = aspectRatio,
                Resolution = resolution,
                Duration = duration,
                NegativePrompt = negativePrompt,
                Style = style,
                Seed = seed,
                Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
            },
            cancellationToken);

        if (notAccepted != null) return notAccepted;
        if (typed == null) return "User input missing.".ToErrorCallToolResponse();

        // Step 2: Build JSON payload
        var jsonBody = JsonSerializer.Serialize(new
        {
            model = "pixverse/v5/text-to-video",
            prompt = typed.Prompt,
            aspect_ratio = typed.AspectRatio.GetEnumMemberValue(),
            resolution = typed.Resolution.GetEnumMemberValue(),
            duration = (int)typed.Duration,
            negative_prompt = typed.NegativePrompt,
            style = typed.Style.GetEnumMemberValue(),
            seed = typed.Seed
        });

        using var client = clientFactory.CreateClient();
        using var request = new HttpRequestMessage(HttpMethod.Post, PIXVERSE_BASE_URL);
        request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
        request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
        request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

        // Step 3: Send request
        using var resp = await client.SendAsync(request, cancellationToken);
        var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
        if (!resp.IsSuccessStatusCode)
            throw new Exception($"{resp.StatusCode}: {jsonResponse}");

        // Step 4: Parse response (returns ID)
        using var doc = JsonDocument.Parse(jsonResponse);
        var id = doc.RootElement.TryGetProperty("id", out var idProp)
            ? idProp.GetString()
            : null;

        if (string.IsNullOrWhiteSpace(id))
            throw new Exception("No generation ID returned from PixVerse API.");

        // Step 5: Return JSON + info text
        return new CallToolResult()
        {
            Content =
            [
                new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = PIXVERSE_BASE_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎬 PixVerse video generation started (ID: {id}). Processing asynchronously."
                }
            ]
        };
    });

    // --- DTOs & Enums ---

    [Description("Please fill in the PixVerse video generation request.")]
    public class AIMLPixVerseVideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Text description of the video scene or action.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("aspect_ratio")]
        [Required]
        [Description("Aspect ratio of the video.")]
        public AspectRatio AspectRatio { get; set; } = AspectRatio.Ratio_16x9;

        [JsonPropertyName("resolution")]
        [Required]
        [Description("Video resolution (360p–1080p).")]
        public Resolution Resolution { get; set; } = Resolution.p720;

        [JsonPropertyName("duration")]
        [Required]
        [Description("Length of video in seconds (5 or 8).")]
        public Duration Duration { get; set; } = Duration.Seconds5;

        [JsonPropertyName("negative_prompt")]
        [Description("Elements to exclude from the generated video.")]
        public string? NegativePrompt { get; set; }

        [JsonPropertyName("style")]
        [Description("Visual style of the generated video.")]
        public VideoStyle Style { get; set; } = VideoStyle.Anime;

        [JsonPropertyName("seed")]
        [Description("Seed for deterministic generation (optional).")]
        public int? Seed { get; set; }

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum AspectRatio
    {
        [EnumMember(Value = "16:9")]
        Ratio_16x9,
        [EnumMember(Value = "4:3")]
        Ratio_4x3,
        [EnumMember(Value = "1:1")]
        Ratio_1x1,
        [EnumMember(Value = "3:4")]
        Ratio_3x4,
        [EnumMember(Value = "9:16")]
        Ratio_9x16,
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum Resolution
    {
        [EnumMember(Value = "360p")]
        p360,
        [EnumMember(Value = "540p")]
        p540,
        [EnumMember(Value = "720p")]
        p720,
        [EnumMember(Value = "1080p")]
        p1080
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum Duration
    {
        [EnumMember(Value = "5")]
        Seconds5 = 5,
        [EnumMember(Value = "8")]
        Seconds8 = 8
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum VideoStyle
    {
        [EnumMember(Value = "anime")]
        Anime,
        [EnumMember(Value = "3d_animation")]
        Animation3D,
        [EnumMember(Value = "clay")]
        Clay,
        [EnumMember(Value = "comic")]
        Comic,
        [EnumMember(Value = "cyberpunk")]
        Cyberpunk
    }


    [Description("Generate a short AI video using SberAI Kandinsky 5 (text-to-video). Provide a prompt describing the scene or action. Returns a generation ID for asynchronous processing.")]
    [McpServerTool(
        Title = "Generate video with SberAI Kandinsky 5",
        Name = "aiml_video_sberai_kandinsky5_generate",
        Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_SberAIKandinsky5Generate(
        [Description("Prompt describing the video content (scene, subject, or action)."), MaxLength(4000)] string prompt,
        IServiceProvider serviceProvider,
        RequestContext<CallToolRequestParams> requestContext,
        [Description("Aspect ratio of the generated video. Default: 16:9")] SberAspectRatio aspectRatio = SberAspectRatio.Ratio_16x9,
        [Description("Length of the generated video in seconds (5 or 10).")] SberDuration duration = SberDuration.Seconds5,
        [Description("Number of inference steps. Higher values improve quality but take longer. Default: 30"), Range(1, 1000)] int numInferenceSteps = 30,
        [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
        CancellationToken cancellationToken = default)
        => await requestContext.WithExceptionCheck(async () =>
    {
        ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);

        var settings = serviceProvider.GetRequiredService<AIMLSettings>();
        var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

        // Step 1: Ask user for any missing input
        var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
            new AIMLSberVideoRequest
            {
                Prompt = prompt,
                AspectRatio = aspectRatio,
                Duration = duration,
                NumInferenceSteps = numInferenceSteps,
                Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
            },
            cancellationToken);

        if (notAccepted != null) return notAccepted;
        if (typed == null) return "User input missing.".ToErrorCallToolResponse();

        // Step 2: Build JSON payload
        var jsonBody = JsonSerializer.Serialize(new
        {
            model = "sber-ai/kandinsky5-t2v",
            prompt = typed.Prompt,
            aspect_ratio = typed.AspectRatio.GetEnumMemberValue(),
            duration = (int)typed.Duration,
            num_inference_steps = typed.NumInferenceSteps
        });

        using var client = clientFactory.CreateClient();
        using var request = new HttpRequestMessage(HttpMethod.Post, BASE_URL);
        request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
        request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
        request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

        // Step 3: Send request
        using var resp = await client.SendAsync(request, cancellationToken);
        var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
        if (!resp.IsSuccessStatusCode)
            throw new Exception($"{resp.StatusCode}: {jsonResponse}");

        // Step 4: Parse response
        using var doc = JsonDocument.Parse(jsonResponse);
        var id = doc.RootElement.TryGetProperty("id", out var idProp)
            ? idProp.GetString()
            : null;

        if (string.IsNullOrWhiteSpace(id))
            throw new Exception("No generation ID returned from SberAI API.");

        // Step 5: Return result
        return new CallToolResult()
        {
            Content =
            [
                new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = BASE_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎞️ SberAI Kandinsky 5 video generation started (ID: {id}). Processing asynchronously."
                }
            ]
        };
    });

    // --- DTOs & Enums ---

    [Description("Please fill in the SberAI Kandinsky 5 video generation request.")]
    public class AIMLSberVideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Text description of the scene or action to generate.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("aspect_ratio")]
        [Required]
        [Description("Aspect ratio of the video.")]
        public SberAspectRatio AspectRatio { get; set; } = SberAspectRatio.Ratio_16x9;

        [JsonPropertyName("duration")]
        [Required]
        [Description("Video duration in seconds.")]
        public SberDuration Duration { get; set; } = SberDuration.Seconds5;

        [JsonPropertyName("num_inference_steps")]
        [Range(1, 1000)]
        [Description("Number of inference steps for sampling. Higher = better quality, slower generation.")]
        public int NumInferenceSteps { get; set; } = 30;

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum SberAspectRatio
    {
        [EnumMember(Value = "16:9")]
        Ratio_16x9,
        [EnumMember(Value = "9:16")]
        Ratio_9x16,
        [EnumMember(Value = "1:1")]
        Ratio_1x1
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum SberDuration
    {
        [EnumMember(Value = "5")]
        Seconds5 = 5,
        [EnumMember(Value = "10")]
        Seconds10 = 10
    }

    [Description("Generate a short AI video using SberAI Kandinsky 5 Distill (text-to-video). Provide a prompt describing the scene or action. Returns a generation ID for asynchronous processing.")]
    [McpServerTool(
     Title = "Generate video with SberAI Kandinsky 5 Distill",
     Name = "aiml_video_sberai_kandinsky5_distill_generate",
     Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_SberAIDistillGenerate(
     [Description("Prompt describing the video content (scene, subject, or action)."), MaxLength(4000)] string prompt,
     IServiceProvider serviceProvider,
     RequestContext<CallToolRequestParams> requestContext,
     [Description("Aspect ratio of the generated video. Default: 16:9")] DistillAspectRatio aspectRatio = DistillAspectRatio.Ratio_16x9,
     [Description("Length of the generated video in seconds (5 or 10).")] DistillDuration duration = DistillDuration.Seconds5,
     [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
     CancellationToken cancellationToken = default)
     => await requestContext.WithExceptionCheck(async () =>
 {
     ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);

     var settings = serviceProvider.GetRequiredService<AIMLSettings>();
     var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

     // Step 1: Ask user for missing inputs
     var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
         new AIMLDistillVideoRequest
         {
             Prompt = prompt,
             AspectRatio = aspectRatio,
             Duration = duration,
             Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
         },
         cancellationToken);

     if (notAccepted != null) return notAccepted;
     if (typed == null) return "User input missing.".ToErrorCallToolResponse();

     // Step 2: Build JSON payload
     var jsonBody = JsonSerializer.Serialize(new
     {
         model = "sber-ai/kandinsky5-distill-t2v",
         prompt = typed.Prompt,
         aspect_ratio = typed.AspectRatio.GetEnumMemberValue(),
         duration = (int)typed.Duration
     });

     using var client = clientFactory.CreateClient();
     using var request = new HttpRequestMessage(HttpMethod.Post, BASE_URL);
     request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
     request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
     request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

     // Step 3: Send request
     using var resp = await client.SendAsync(request, cancellationToken);
     var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
     if (!resp.IsSuccessStatusCode)
         throw new Exception($"{resp.StatusCode}: {jsonResponse}");

     // Step 4: Parse response (ID)
     using var doc = JsonDocument.Parse(jsonResponse);
     var id = doc.RootElement.TryGetProperty("id", out var idProp)
         ? idProp.GetString()
         : null;

     if (string.IsNullOrWhiteSpace(id))
         throw new Exception("No generation ID returned from Distill API.");

     // Step 5: Return response + message
     return new CallToolResult()
     {
         Content =
         [
             new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = BASE_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎬 SberAI Kandinsky 5 Distill video generation started (ID: {id}). Processing asynchronously."
                }
         ]
     };
 });


    [Description("Please fill in the SberAI Kandinsky 5 Distill video generation request.")]
    public class AIMLDistillVideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Text description of the video scene or action.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("aspect_ratio")]
        [Required]
        [Description("Aspect ratio of the video (16:9, 9:16, or 1:1).")]
        public DistillAspectRatio AspectRatio { get; set; } = DistillAspectRatio.Ratio_16x9;

        [JsonPropertyName("duration")]
        [Required]
        [Description("Length of the video in seconds (5 or 10).")]
        public DistillDuration Duration { get; set; } = DistillDuration.Seconds5;

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum DistillAspectRatio
    {
        [EnumMember(Value = "16:9")]
        Ratio_16x9,
        [EnumMember(Value = "9:16")]
        Ratio_9x16,
        [EnumMember(Value = "1:1")]
        Ratio_1x1
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum DistillDuration
    {
        [EnumMember(Value = "5")]
        Seconds5 = 5,
        [EnumMember(Value = "10")]
        Seconds10 = 10
    }

    [Description("Generate a short AI video using Krea WAN-14B (text-to-video). Duration is defined by frame count (16 fps). Returns a generation ID for asynchronous processing.")]
    [McpServerTool(
      Title = "Generate video with Krea WAN-14B",
      Name = "aiml_video_krea_wan14b_generate",
      Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_KreaWAN14BGenerate(
      [Description("Prompt describing the video content (scene, subject, or action)."), MaxLength(4000)] string prompt,
      IServiceProvider serviceProvider,
      RequestContext<CallToolRequestParams> requestContext,
      [Description("Number of frames to generate (18–162, must be 12n+6). Default: 78"), Range(18, 162)] int numFrames = 78,
      [Description("Enable or disable prompt expansion (default: true).")] bool enablePromptExpansion = true,
      [Description("Optional seed for deterministic generation.")] int? seed = null,
      [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
      CancellationToken cancellationToken = default)
      => await requestContext.WithExceptionCheck(async () =>
  {
      ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);

      var settings = serviceProvider.GetRequiredService<AIMLSettings>();
      var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

      // Step 1: Ask user for missing inputs
      var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
          new AIMLKreaWAN14BVideoRequest
          {
              Prompt = prompt,
              NumFrames = numFrames,
              EnablePromptExpansion = enablePromptExpansion,
              Seed = seed,
              Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
          },
          cancellationToken);

      if (notAccepted != null) return notAccepted;
      if (typed == null) return "User input missing.".ToErrorCallToolResponse();

      // Step 2: Build JSON payload
      var jsonBody = JsonSerializer.Serialize(new
      {
          model = "krea/krea-wan-14b/text-to-video",
          prompt = typed.Prompt,
          num_frames = typed.NumFrames,
          enable_prompt_expansion = typed.EnablePromptExpansion,
          seed = typed.Seed
      });

      using var client = clientFactory.CreateClient();
      using var request = new HttpRequestMessage(HttpMethod.Post, BASE_URL);
      request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
      request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
      request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

      // Step 3: Send request
      using var resp = await client.SendAsync(request, cancellationToken);
      var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
      if (!resp.IsSuccessStatusCode)
          throw new Exception($"{resp.StatusCode}: {jsonResponse}");

      // Step 4: Parse response
      using var doc = JsonDocument.Parse(jsonResponse);
      var id = doc.RootElement.TryGetProperty("id", out var idProp)
          ? idProp.GetString()
          : null;

      if (string.IsNullOrWhiteSpace(id))
          throw new Exception("No generation ID returned from Krea API.");

      // Step 5: Return JSON + info text
      return new CallToolResult()
      {
          Content =
          [
              new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = BASE_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎥 Krea WAN-14B video generation started (ID: {id}). Processing asynchronously (≈ {typed.NumFrames / 16.0:F1}s at 16 fps)."
                }
          ]
      };
  });

    // --- DTOs & Schema ---

    [Description("Please fill in the Krea WAN-14B video generation request.")]
    public class AIMLKreaWAN14BVideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Text description of the video scene, subject, or action.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("num_frames")]
        [Range(18, 162)]
        [Description("Number of frames to generate (must be 12n+6).")]
        public int NumFrames { get; set; } = 78;

        [JsonPropertyName("enable_prompt_expansion")]
        [Description("Enable prompt expansion for richer generation.")]
        public bool EnablePromptExpansion { get; set; } = true;

        [JsonPropertyName("seed")]
        [Description("Optional seed for deterministic output.")]
        public int? Seed { get; set; }

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [Description("Transform an existing video using Krea WAN-14B (video-to-video). Upload or link a reference video and describe the desired transformation.")]
    [McpServerTool(
       Title = "Transform video with Krea WAN-14B (Video-to-Video)",
       Name = "aiml_video_krea_wan14b_v2v_generate",
       Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_KreaWAN14BVideoToVideo(
       [Description("Prompt describing how to transform or modify the reference video.")] string prompt,
       [Description("Input video URL (SharePoint, OneDrive, or HTTPS).")] string videoUrl,
       IServiceProvider serviceProvider,
       RequestContext<CallToolRequestParams> requestContext,
       [Description("Denoising strength (0.0 keeps original, 1.0 fully regenerates). Default: 0.85"), Range(0.0, 1.0)] double strength = 0.85,
       [Description("Enable prompt expansion for richer results.")] bool enablePromptExpansion = true,
       [Description("Optional seed for deterministic results.")] int? seed = null,
       [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
       CancellationToken cancellationToken = default)
       => await requestContext.WithExceptionCheck(async () =>
   {
       ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);
       ArgumentNullException.ThrowIfNullOrWhiteSpace(videoUrl);

       var settings = serviceProvider.GetRequiredService<AIMLSettings>();
       var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();
       var downloadService = serviceProvider.GetRequiredService<DownloadService>();

       // Step 1: Download source video (if SharePoint/OneDrive or local)
       var files = await downloadService.DownloadContentAsync(serviceProvider, requestContext.Server, videoUrl, cancellationToken);
       var file = files.FirstOrDefault() ?? throw new Exception("Video file not found or could not be downloaded.");

       // Step 2: Convert to Base64 data URI
       var base64 = Convert.ToBase64String(file.Contents.ToArray());
       var dataUri = $"data:video/mp4;base64,{base64}";

       // Step 3: Ask user for any missing input
       var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
           new AIMLKreaWAN14BVideoToVideoRequest
           {
               Prompt = prompt,
               VideoUrl = videoUrl,
               Strength = strength,
               EnablePromptExpansion = enablePromptExpansion,
               Seed = seed,
               Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
           },
           cancellationToken);

       if (notAccepted != null) return notAccepted;
       if (typed == null) return "User input missing.".ToErrorCallToolResponse();

       // Step 4: Build JSON payload
       var jsonBody = JsonSerializer.Serialize(new
       {
           model = "krea/krea-wan-14b/video-to-video",
           prompt = typed.Prompt,
           video_url = dataUri,
           strength = typed.Strength,
           enable_prompt_expansion = typed.EnablePromptExpansion,
           seed = typed.Seed
       });

       using var client = clientFactory.CreateClient();
       using var request = new HttpRequestMessage(HttpMethod.Post, BASE_URL);
       request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
       request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
       request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

       // Step 5: Send request
       using var resp = await client.SendAsync(request, cancellationToken);
       var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
       if (!resp.IsSuccessStatusCode)
           throw new Exception($"{resp.StatusCode}: {jsonResponse}");

       // Step 6: Parse response (ID)
       using var doc = JsonDocument.Parse(jsonResponse);
       var id = doc.RootElement.TryGetProperty("id", out var idProp)
           ? idProp.GetString()
           : null;

       if (string.IsNullOrWhiteSpace(id))
           throw new Exception("No generation ID returned from Krea Video-to-Video API.");

       // Step 7: Return raw JSON + confirmation
       return new CallToolResult()
       {
           Content =
           [
               new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = BASE_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎞️ Krea WAN-14B Video-to-Video generation started (ID: {id}). Processing asynchronously."
                }
           ]
       };
   });

    // --- DTO ---

    [Description("Please fill in the Krea WAN-14B video-to-video generation request.")]
    public class AIMLKreaWAN14BVideoToVideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Prompt describing how the reference video should be modified.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("video_url")]
        [Required]
        [Description("HTTPS or SharePoint/OneDrive link to the source video.")]
        public string VideoUrl { get; set; } = default!;

        [JsonPropertyName("strength")]
        [Range(0.0, 1.0)]
        [Description("Denoising strength (0 = original, 1 = full regeneration).")]
        public double Strength { get; set; } = 0.85;

        [JsonPropertyName("enable_prompt_expansion")]
        [Description("Enable prompt expansion for richer results.")]
        public bool EnablePromptExpansion { get; set; } = true;

        [JsonPropertyName("seed")]
        [Description("Optional seed for deterministic output.")]
        public int? Seed { get; set; }

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [Description("Generate a high-quality AI video using Google Veo 3.1 (text-to-video). Includes prompt enhancement, audio generation, and auto-fix features.")]
    [McpServerTool(
        Title = "Generate video with Google Veo 3.1",
        Name = "aiml_video_google_veo31_generate",
        Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_GoogleVeo31Generate(
        [Description("Prompt describing the video content (scene, subject, or action)."), MaxLength(4000)] string prompt,
        IServiceProvider serviceProvider,
        RequestContext<CallToolRequestParams> requestContext,
        [Description("Aspect ratio of the generated video. Default: 16:9")] VeoAspectRatio aspectRatio = VeoAspectRatio.Ratio_16x9,
        [Description("Duration of the video in seconds (4, 6 or 8).")] int duration = 8,
        [Description("Video resolution (720p or 1080p). Default: 1080p")] VeoResolution resolution = VeoResolution.p1080,
        [Description("Optional description of what to avoid in the video.")] string? negativePrompt = null,
        [Description("Enable prompt enhancement using AI. Default: true")] bool enhancePrompt = true,
        [Description("Generate audio with the video. Default: true")] bool generateAudio = true,
        [Description("Enable automatic fixing of problematic prompts. Default: true")] bool autoFix = true,
        [Description("Optional seed for deterministic generation.")] int? seed = null,
        [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
        CancellationToken cancellationToken = default)
        => await requestContext.WithExceptionCheck(async () =>
    {
        ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);

        var settings = serviceProvider.GetRequiredService<AIMLSettings>();
        var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

        // Step 1: Ask user for missing input
        var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
            new AIMLVeo31VideoRequest
            {
                Prompt = prompt,
                AspectRatio = aspectRatio,
                Duration = duration,
                Resolution = resolution,
                NegativePrompt = negativePrompt,
                EnhancePrompt = enhancePrompt,
                GenerateAudio = generateAudio,
                AutoFix = autoFix,
                Seed = seed,
                Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
            },
            cancellationToken);

        if (notAccepted != null) return notAccepted;
        if (typed == null) return "User input missing.".ToErrorCallToolResponse();

        // Step 2: Build JSON payload
        var jsonBody = JsonSerializer.Serialize(new
        {
            model = "google/veo-3.1-t2v",
            prompt = typed.Prompt,
            aspect_ratio = typed.AspectRatio.GetEnumMemberValue(),
            duration = (int)typed.Duration,
            resolution = typed.Resolution.GetEnumMemberValue(),
            negative_prompt = typed.NegativePrompt,
            enhance_prompt = typed.EnhancePrompt,
            generate_audio = typed.GenerateAudio,
            seed = typed.Seed,
            auto_fix = typed.AutoFix
        });

        using var client = clientFactory.CreateClient();
        using var request = new HttpRequestMessage(HttpMethod.Post, BASE_URL);
        request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
        request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
        request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

        // Step 3: Send request
        using var resp = await client.SendAsync(request, cancellationToken);
        var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
        if (!resp.IsSuccessStatusCode)
            throw new Exception($"{resp.StatusCode}: {jsonResponse}");

        // Step 4: Parse response (ID)
        using var doc = JsonDocument.Parse(jsonResponse);
        var id = doc.RootElement.TryGetProperty("id", out var idProp)
            ? idProp.GetString()
            : null;

        if (string.IsNullOrWhiteSpace(id))
            throw new Exception("No generation ID returned from Google Veo API.");

        // Step 5: Return raw JSON + user info
        return new CallToolResult()
        {
            Content =
            [
                new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = BASE_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎬 Google Veo 3.1 video generation started (ID: {id}). Processing asynchronously."
                }
            ]
        };
    });

    // --- DTOs & Enums ---

    [Description("Please fill in the Google Veo 3.1 video generation request.")]
    public class AIMLVeo31VideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Text description of the desired video scene or action.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("aspect_ratio")]
        [Required]
        [Description("Aspect ratio of the video.")]
        public VeoAspectRatio AspectRatio { get; set; } = VeoAspectRatio.Ratio_16x9;

        [JsonPropertyName("duration")]
        [Required]
        [Description("Video duration in seconds.")]
        public int Duration { get; set; } = 8;

        [JsonPropertyName("resolution")]
        [Required]
        [Description("Video resolution (720p or 1080p).")]
        public VeoResolution Resolution { get; set; } = VeoResolution.p1080;

        [JsonPropertyName("negative_prompt")]
        [Description("Elements to exclude from the generated video.")]
        public string? NegativePrompt { get; set; }

        [JsonPropertyName("enhance_prompt")]
        [Description("Whether to enhance the prompt using AI.")]
        public bool EnhancePrompt { get; set; } = true;

        [JsonPropertyName("generate_audio")]
        [Description("Generate audio along with video.")]
        public bool GenerateAudio { get; set; } = true;

        [JsonPropertyName("auto_fix")]
        [Description("Automatically fix invalid or blocked prompts.")]
        public bool AutoFix { get; set; } = true;

        [JsonPropertyName("seed")]
        [Description("Optional seed for deterministic output.")]
        public int? Seed { get; set; }

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum VeoAspectRatio
    {
        [EnumMember(Value = "16:9")]
        Ratio_16x9,
        [EnumMember(Value = "9:16")]
        Ratio_9x16,
        [EnumMember(Value = "1:1")]
        Ratio_1x1
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum VeoResolution
    {
        [EnumMember(Value = "720p")]
        p720,
        [EnumMember(Value = "1080p")]
        p1080
    }

    [Description("Generate a fast AI video using Google Veo 3.1 Fast (text-to-video). Same quality as Veo 3.1 but optimized for faster inference.")]
    [McpServerTool(
       Title = "Generate video with Google Veo 3.1 Fast",
       Name = "aiml_video_google_veo31fast_generate",
       Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_GoogleVeo31FastGenerate(
       [Description("Prompt describing the video content (scene, subject, or action)."), MaxLength(4000)] string prompt,
       IServiceProvider serviceProvider,
       RequestContext<CallToolRequestParams> requestContext,
       [Description("Aspect ratio of the generated video. Default: 16:9")] VeoAspectRatio aspectRatio = VeoAspectRatio.Ratio_16x9,
       [Description("Duration of the video in seconds (4, 6 or 8).")] int duration = 8,
       [Description("Video resolution (720p or 1080p). Default: 1080p")] VeoResolution resolution = VeoResolution.p1080,
       [Description("Optional description of what to avoid in the video.")] string? negativePrompt = null,
       [Description("Enable prompt enhancement using AI. Default: true")] bool enhancePrompt = true,
       [Description("Generate audio with the video. Default: true")] bool generateAudio = true,
       [Description("Enable automatic fixing of problematic prompts. Default: true")] bool autoFix = true,
       [Description("Optional seed for deterministic generation.")] int? seed = null,
       [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
       CancellationToken cancellationToken = default)
       => await requestContext.WithExceptionCheck(async () =>
   {
       ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);

       var settings = serviceProvider.GetRequiredService<AIMLSettings>();
       var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

       // Step 1: ask user for any missing input
       var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
           new AIMLVeo31FastVideoRequest
           {
               Prompt = prompt,
               AspectRatio = aspectRatio,
               Duration = duration,
               Resolution = resolution,
               NegativePrompt = negativePrompt,
               EnhancePrompt = enhancePrompt,
               GenerateAudio = generateAudio,
               AutoFix = autoFix,
               Seed = seed,
               Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
           },
           cancellationToken);

       if (notAccepted != null) return notAccepted;
       if (typed == null) return "User input missing.".ToErrorCallToolResponse();

       // Step 2: build JSON payload
       var jsonBody = JsonSerializer.Serialize(new
       {
           model = "google/veo-3.1-t2v-fast",
           prompt = typed.Prompt,
           aspect_ratio = typed.AspectRatio.GetEnumMemberValue(),
           duration = (int)typed.Duration,
           resolution = typed.Resolution.GetEnumMemberValue(),
           negative_prompt = typed.NegativePrompt,
           enhance_prompt = typed.EnhancePrompt,
           generate_audio = typed.GenerateAudio,
           seed = typed.Seed,
           auto_fix = typed.AutoFix
       });

       using var client = clientFactory.CreateClient();
       using var request = new HttpRequestMessage(HttpMethod.Post, BASE_URL);
       request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
       request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
       request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

       // Step 3: send request
       using var resp = await client.SendAsync(request, cancellationToken);
       var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
       if (!resp.IsSuccessStatusCode)
           throw new Exception($"{resp.StatusCode}: {jsonResponse}");

       // Step 4: parse response
       using var doc = JsonDocument.Parse(jsonResponse);
       var id = doc.RootElement.TryGetProperty("id", out var idProp)
           ? idProp.GetString()
           : null;

       if (string.IsNullOrWhiteSpace(id))
           throw new Exception("No generation ID returned from Google Veo Fast API.");

       // Step 5: return JSON + info
       return new CallToolResult()
       {
           Content =
           [
               new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = BASE_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"⚡ Google Veo 3.1 Fast video generation started (ID: {id}). Processing asynchronously."
                }
           ]
       };
   });

    // --- DTO & Enums ---

    [Description("Please fill in the Google Veo 3.1 Fast video generation request.")]
    public class AIMLVeo31FastVideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Text description of the video scene or action.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("aspect_ratio")]
        [Required]
        public VeoAspectRatio AspectRatio { get; set; } = VeoAspectRatio.Ratio_16x9;

        [JsonPropertyName("duration")]
        [Required]
        public int Duration { get; set; } = 8;

        [JsonPropertyName("resolution")]
        [Required]
        public VeoResolution Resolution { get; set; } = VeoResolution.p1080;

        [JsonPropertyName("negative_prompt")]
        public string? NegativePrompt { get; set; }

        [JsonPropertyName("enhance_prompt")]
        public bool EnhancePrompt { get; set; } = true;

        [JsonPropertyName("generate_audio")]
        public bool GenerateAudio { get; set; } = true;

        [JsonPropertyName("auto_fix")]
        public bool AutoFix { get; set; } = true;

        [JsonPropertyName("seed")]
        public int? Seed { get; set; }

        [JsonPropertyName("filename")]
        [Required]
        public string Filename { get; set; } = default!;
    }

    private static readonly string MINIMAX_VIDEO_URL = "https://api.aimlapi.com/v2/generate/video/minimax/generation";

    [Description("Generate a short AI video using MiniMax Hailuo-02. Optionally specify first and last frame images to guide the animation.")]
    [McpServerTool(
        Title = "Generate video with MiniMax Hailuo-02",
        Name = "aiml_video_minimax_hailuo02_generate",
        Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_MiniMaxHailuo02Generate(
        [Description("Prompt describing the video content (scene, subject, or action)."), MaxLength(2000)] string prompt,
        IServiceProvider serviceProvider,
        RequestContext<CallToolRequestParams> requestContext,
        [Description("Optional image URL or SharePoint/OneDrive link for the first frame.")] string? firstFrameImage = null,
        [Description("Optional image URL or SharePoint/OneDrive link for the last frame.")] string? lastImageUrl = null,
        [Description("Video duration in seconds (6–10).")] MiniMaxDuration duration = MiniMaxDuration.Seconds6,
        [Description("Video resolution. Default: 768P.")] MiniMaxResolution resolution = MiniMaxResolution.P768,
        [Description("Automatically optimize prompt for better quality (default: true).")] bool promptOptimizer = true,
        [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
        CancellationToken cancellationToken = default)
        => await requestContext.WithExceptionCheck(async () =>
    {
        ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);

        var settings = serviceProvider.GetRequiredService<AIMLSettings>();
        var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();
        var downloadService = serviceProvider.GetRequiredService<DownloadService>();

        string? firstFrameData = null;
        string? lastFrameData = null;

        // Step 1: Download first frame (if provided)
        if (!string.IsNullOrWhiteSpace(firstFrameImage))
        {
            var files = await downloadService.DownloadContentAsync(serviceProvider, requestContext.Server, firstFrameImage, cancellationToken);
            var file = files.FirstOrDefault();
            if (file != null)
            {
                var base64 = Convert.ToBase64String(file.Contents.ToArray());
                firstFrameData = $"data:image/png;base64,{base64}";
            }
            else firstFrameData = firstFrameImage;
        }

        // Step 2: Download last frame (if provided)
        if (!string.IsNullOrWhiteSpace(lastImageUrl))
        {
            var files = await downloadService.DownloadContentAsync(serviceProvider, requestContext.Server, lastImageUrl, cancellationToken);
            var file = files.FirstOrDefault();
            if (file != null)
            {
                var base64 = Convert.ToBase64String(file.Contents.ToArray());
                lastFrameData = $"data:image/png;base64,{base64}";
            }
            else lastFrameData = lastImageUrl;
        }

        // Step 3: Ask user for missing info
        var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
            new AIMLMiniMaxHailuo02VideoRequest
            {
                Prompt = prompt,
                //  FirstFrameImage = firstFrameImage,
                // LastImageUrl = lastImageUrl,
                Duration = duration,
                Resolution = resolution,
                PromptOptimizer = promptOptimizer,
                Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp4")
            },
            cancellationToken);
        if (notAccepted != null) return notAccepted;
        if (typed == null) return "User input missing.".ToErrorCallToolResponse();

        // Step 4: Build JSON payload
        var jsonBody = JsonSerializer.Serialize(new
        {
            model = "minimax/hailuo-02",
            prompt = typed.Prompt,
            first_frame_image = firstFrameData,
            last_image_url = lastFrameData,
            duration = (int)typed.Duration,
            resolution = typed.Resolution.GetEnumMemberValue(),
            prompt_optimizer = typed.PromptOptimizer
        });

        using var client = clientFactory.CreateClient();
        using var request = new HttpRequestMessage(HttpMethod.Post, MINIMAX_VIDEO_URL);
        request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
        request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
        request.Content = new StringContent(jsonBody, Encoding.UTF8, MimeTypes.Json);

        // Step 5: Send request
        using var resp = await client.SendAsync(request, cancellationToken);
        var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
        if (!resp.IsSuccessStatusCode)
            throw new Exception($"{resp.StatusCode}: {jsonResponse}");

        // Step 6: Parse response (ID)
        using var doc = JsonDocument.Parse(jsonResponse);
        var id = doc.RootElement.TryGetProperty("id", out var idProp)
            ? idProp.GetString()
            : null;
        if (string.IsNullOrWhiteSpace(id))
            throw new Exception("No generation ID returned from MiniMax Hailuo-02 API.");

        // Step 7: Return result
        return new CallToolResult()
        {
            Content =
            [
                new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = MINIMAX_VIDEO_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎥 MiniMax Hailuo-02 video generation started (ID: {id}). Processing asynchronously."
                }
            ]
        };
    });

    // --- DTOs & Enums ---

    [Description("Please fill in the MiniMax Hailuo-02 video generation request.")]
    public class AIMLMiniMaxHailuo02VideoRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Prompt describing the desired video (scene, subject, or action).")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("duration")]
        [Required]
        [Description("Length of the generated video (6–10 seconds).")]
        public MiniMaxDuration Duration { get; set; } = MiniMaxDuration.Seconds6;

        [JsonPropertyName("resolution")]
        [Required]
        [Description("Video resolution (768P or 1080P).")]
        public MiniMaxResolution Resolution { get; set; } = MiniMaxResolution.P768;

        [JsonPropertyName("prompt_optimizer")]
        [Description("Automatically optimize the prompt (default: true).")]
        public bool PromptOptimizer { get; set; } = true;

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum MiniMaxDuration
    {
        [EnumMember(Value = "6")]
        Seconds6 = 6,
        [EnumMember(Value = "10")]
        Seconds10 = 10
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum MiniMaxResolution
    {
        [EnumMember(Value = "768P")]
        P768,
        [EnumMember(Value = "1080P")]
        P1080
    }

    private static readonly string RUNWAY_URL = "https://api.aimlapi.com/v2/generate/video/runway/generation";

    [Description("Transform a video using Runway Gen-4 Aleph. Provide a video and a prompt describing the desired transformation. The input video will be base64-encoded automatically.")]
    [McpServerTool(
        Title = "Transform video with Runway Gen-4 Aleph",
        Name = "aiml_video_runway_gen4aleph_generate",
        Destructive = false)]
    public static async Task<CallToolResult?> AIMLVideo_RunwayGen4AlephGenerate(
        [Description("Prompt describing the desired transformation of the input video.")] string prompt,
        [Description("Input video URL (SharePoint, OneDrive, or HTTPS).")] string videoUrl,
        IServiceProvider serviceProvider,
        RequestContext<CallToolRequestParams> requestContext,
        [Description("Output duration in seconds. Default: 5")] RunwayDuration duration = RunwayDuration.Seconds5,
        [Description("Output frame size. Default: 1280:720")] RunwayFrameSize frameSize = RunwayFrameSize.Size1280x720,
        [Description("Optional seed for deterministic generation.")] uint? seed = null,
        [Description("Optional image references influencing style or content.")] List<RunwayReference>? references = null,
        [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
        CancellationToken cancellationToken = default)
        => await requestContext.WithExceptionCheck(async () =>
    {
        ArgumentNullException.ThrowIfNullOrWhiteSpace(prompt);
        ArgumentNullException.ThrowIfNullOrWhiteSpace(videoUrl);

        var settings = serviceProvider.GetRequiredService<AIMLSettings>();
        var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();
        var downloadService = serviceProvider.GetRequiredService<DownloadService>();

        // Step 1: Download and encode input video
        var files = await downloadService.DownloadContentAsync(serviceProvider, requestContext.Server, videoUrl, cancellationToken);
        var file = files.FirstOrDefault() ?? throw new Exception("Video file not found or could not be downloaded.");
        var base64 = Convert.ToBase64String(file.Contents.ToArray());
        var dataUri = $"data:video/mp4;base64,{base64}";

        // Step 2: Build JSON body (no elicitation for video input)
        var body = new
        {
            model = "runway/gen4_aleph",
            video_url = dataUri,
            prompt,
            duration = (int)duration,
            frame_size = frameSize.GetEnumMemberValue(),
            seed,
            references
        };

        using var client = clientFactory.CreateClient();
        using var request = new HttpRequestMessage(HttpMethod.Post, RUNWAY_URL);
        request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
        request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
        request.Content = new StringContent(JsonSerializer.Serialize(body), Encoding.UTF8, MimeTypes.Json);

        // Step 3: Send request
        using var resp = await client.SendAsync(request, cancellationToken);
        var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
        if (!resp.IsSuccessStatusCode)
            throw new Exception($"{resp.StatusCode}: {jsonResponse}");

        // Step 4: Parse response
        using var doc = JsonDocument.Parse(jsonResponse);
        var id = doc.RootElement.TryGetProperty("id", out var idProp)
            ? idProp.GetString()
            : null;
        if (string.IsNullOrWhiteSpace(id))
            throw new Exception("No generation ID returned from Runway API.");

        // Step 5: Return result
        return new CallToolResult()
        {
            Content =
            [
                new EmbeddedResourceBlock()
                {
                    Resource = new TextResourceContents()
                    {
                        MimeType = MimeTypes.Json,
                        Text = doc.RootElement.ToJsonString(),
                        Uri = RUNWAY_URL
                    }
                },
                new TextContentBlock()
                {
                    Text = $"🎞 Runway Gen-4 Aleph video generation started (ID: {id}). Processing asynchronously."
                }
            ]
        };
    });

    // --- DTOs & Enums ---

    [Description("Reference object for Runway video generation.")]
    public class RunwayReference
    {
        [JsonPropertyName("type")]
        [Description("Reference type, e.g., 'image'.")]
        public string Type { get; set; } = "image";

        [JsonPropertyName("url")]
        [Description("HTTPS URL to the reference image.")]
        public string Url { get; set; } = default!;
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum RunwayDuration
    {
        [EnumMember(Value = "5")]
        Seconds5 = 5
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum RunwayFrameSize
    {
        [EnumMember(Value = "1280:720")]
        Size1280x720,
        [EnumMember(Value = "720:1280")]
        Size720x1280,
        [EnumMember(Value = "1104:832")]
        Size1104x832,
        [EnumMember(Value = "832:1104")]
        Size832x1104,
        [EnumMember(Value = "960:960")]
        Size960x960,
        [EnumMember(Value = "1584:672")]
        Size1584x672,
        [EnumMember(Value = "848:480")]
        Size848x480,
        [EnumMember(Value = "640:480")]
        Size640x480
    }


}
